Esta documenta√ß√£o consolida a vis√£o estrat√©gica, arquitetural e funcional do DiscoverySpark. O objetivo aqui √© fornecer uma vis√£o clara de como o projeto transforma dados brutos em intelig√™ncia acion√°vel, servindo como uma base s√≥lida para apresenta√ß√µes ou expans√µes futuras.

üìë Documenta√ß√£o Estrat√©gica: DiscoverySpark
1. Vis√£o Geral
O DiscoverySpark √© uma engine de Automated Feature Engineering (AFE) e Discovery Analytics. A ideia central √© democratizar a ci√™ncia de dados complexa, permitindo que usu√°rios de neg√≥cios ou analistas identifiquem padr√µes ocultos em bases de dados relacionais sem a necessidade de escrever queries SQL exaustivas ou modelos de ML complexos manualmente.

2. O Problema vs. A Solu√ß√£o
O Problema: Em bancos de dados relacionais, os insights mais valiosos est√£o escondidos no cruzamento entre tabelas (Pai x Filho). Extrair isso exige muito tempo de engenharia de dados.

A Solu√ß√£o DiscoverySpark: Utiliza a tecnologia de Deep Feature Synthesis (DFS) para criar milhares de hip√≥teses estat√≠sticas automaticamente, test√°-las contra um alvo (Target) e traduzir as melhores para linguagem humana.

3. Arquitetura do Sistema
O projeto √© dividido em quatro camadas fundamentais:

A. Camada de Ingest√£o e Mapeamento
O sistema l√™ arquivos CSV e interpreta um arquivo de configura√ß√£o sem√¢ntica (mapeamento.txt). Isso permite que o motor entenda quem √© a entidade principal (Pai) e onde est√£o os eventos detalhados (Filho).

B. Camada de S√≠ntese (The Engine)
Utilizando o framework Featuretools, o DiscoverySpark realiza agrega√ß√µes profundas.

Exemplo: Se a tabela pai √© Clientes e a filha √© Vendas, a engine cria automaticamente m√©tricas como: "M√©dia de valor nos √∫ltimos 30 dias", "Soma total de compras no fim de semana", etc.

C. Camada Anal√≠tica e Direcionamento
Diferente de um modelo de "caixa preta", o DiscoverySpark foca em Explicabilidade:

Random Forest: Para medir o poder explicativo (Import√¢ncia).

Correla√ß√£o de Pearson: Para definir a "Dire√ß√£o do Insight" (se o comportamento ajuda ou atrapalha o resultado final).

D. Camada de Tradu√ß√£o e Consumo (Interface)
Os nomes t√©cnicos s√£o convertidos por um motor sem√¢ntico para o Dashboard. O resultado n√£o √© SUM(vendas.valor), mas sim "Soma total de valor em vendas".

4. Diferenciais do DiscoverySpark
Linguagem de Neg√≥cio: Traduz estat√≠stica pesada em frases acion√°veis (Ex: "Quanto maior este valor, menor a chance de Churn").

Visualiza√ß√£o √Ågil: Dashboard via terminal que permite auditoria r√°pida de resultados.

Portabilidade: Gera arquivos Markdown que podem ser compartilhados via GitHub, Slack ou documenta√ß√µes internas.

Agagn√≥stico de Dados: Funciona para Varejo (Churn), Finan√ßas (Risco), Log√≠stica (Atrasos) ou qualquer cen√°rio relacional.

5. Roadmap de Evolu√ß√£o
Para transformar o DiscoverySpark em um produto de n√≠vel enterprise, os pr√≥ximos passos sugeridos s√£o:

An√°lise Temporal: Adicionar janelas de tempo (Ex: "Como este comportamento mudou nos √∫ltimos 3 meses?").

Interface Web: Converter o Dashboard de terminal para uma aplica√ß√£o visual (Streamlit ou React).

Conectores SQL: Ler dados diretamente de bancos como PostgreSQL, MySQL ou BigQuery.

Sugest√£o de A√ß√£o: O sistema sugerir uma a√ß√£o baseada no insight (Ex: "Este grupo de clientes tem alto risco, envie um cupom de desconto").

6. Fluxo de Trabalho do Usu√°rio
Prepara√ß√£o: Salvar CSVs em /datasets.

Configura√ß√£o: Declarar a rela√ß√£o em mapeamento/mapeamento.txt.

Processamento: Rodar app.py com o alvo desejado.

Decis√£o: Consultar o dashboard.py para obter os 10 insights mais poderosos.

DiscoverySpark ‚Äî Transformando rela√ß√µes de dados em decis√µes inteligentes.
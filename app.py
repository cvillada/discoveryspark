import os
import argparse
import warnings
import pandas as pd
import featuretools as ft
import numpy as np
from datetime import datetime
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.preprocessing import LabelEncoder

# Suprime avisos espec√≠ficos do woodwork e featuretools
warnings.filterwarnings('ignore', message='Could not infer format')
warnings.filterwarnings('ignore', message='pkg_resources is deprecated')
warnings.filterwarnings('ignore', category=FutureWarning, module='featuretools')

# Configura√ß√£o de interface
console = Console()

def formatar_impacto(valor):
    """
    Formata valores de impacto de forma inteligente:
    - Para valores >= 0.01: mostra como porcentagem com 2 casas decimais
    - Para valores entre 0.001 e 0.01: mostra como porcentagem com 4 casas decimais
    - Para valores entre 0.0001 e 0.001: mostra como porcentagem com 6 casas decimais
    - Para valores < 0.0001: mostra em nota√ß√£o cient√≠fica
    """
    if valor >= 0.01:
        return f"{valor:.2%}"
    elif valor >= 0.001:
        return f"{valor:.4%}"
    elif valor >= 0.0001:
        return f"{valor:.6%}"
    else:
        return f"{valor:.2e}"

def setup_environment():
    """Garante a exist√™ncia das pastas do projeto."""
    for folder in ['datasets', 'mapeamento', 'resultados']:
        if not os.path.exists(folder):
            os.makedirs(folder)

def parse_mapping_file():
    """Interpreta a l√≥gica: tabela:pai|id#tabela:filho|id"""
    try:
        with open("mapeamento/mapeamento.txt", "r") as f:
            line = f.readline().strip()
            if not line: return None
        
        tables_raw = line.split('#')
        parsed = []
        for item in tables_raw:
            info, keys_raw = item.split('|')
            name, role = info.split(':')
            keys = keys_raw.split(';')
            parsed.append({'name': name, 'role': role, 'keys': keys})
        return parsed
    except Exception as e:
        console.print(f"[red]Erro ao ler mapeamento.txt: {e}[/red]")
        return None

def traduzir_feature(nome_tecnico):
    """Converte termos t√©cnicos do Featuretools para linguagem de neg√≥cios."""
    traducoes = {
        "SUM": "Soma total de",
        "MEAN": "M√©dia de",
        "COUNT": "Quantidade total de",
        "MAX": "Valor m√°ximo de",
        "MIN": "Valor m√≠nimo de",
        "STD": "Varia√ß√£o de",
        "DAY": "Dia do evento",
        "MONTH": "M√™s do evento",
        "WEEKDAY": "Dia da semana"
    }
    nome = nome_tecnico
    for eng, pt in traducoes.items():
        if eng in nome:
            nome = nome.replace(eng, pt)
    nome = nome.replace("(", " ").replace(")", "")
    if "." in nome:
        partes = nome.split(".")
        nome = f"{partes[1]} em {partes[0]}"
    return nome.capitalize()

def validate_targets(df, target_string):
    """Valida se os targets especificados s√£o apropriados para an√°lise."""
    if ',' in target_string:
        targets = [t.strip() for t in target_string.split(',')]
    else:
        targets = [target_string.strip()]
    
    # Identifica chaves comuns (campos que s√£o tipicamente identificadores)
    common_keys = {'id_', '_id', 'cod_', '_cod', 'key', '_key', 'numero', '_numero', 'cpf', 'cnpj', 'matricula'}
    
    inappropriate_targets = []
    appropriate_targets = []
    
    for t in targets:
        if t not in df.columns:
            inappropriate_targets.append(f"{t} (n√£o encontrado no dataset)")
        else:
            # Verifica se parece ser uma chave
            is_key = any(keyword in t.lower() for keyword in common_keys)
            
            # Verifica se tem muitos valores √∫nicos (caracter√≠stica de chave)
            unique_ratio = df[t].nunique() / len(df)
            many_unique = unique_ratio > 0.8  # Mais de 80% valores √∫nicos
            
            if is_key or many_unique:
                inappropriate_targets.append(f"{t} (parece ser uma chave/identificador)")
            else:
                appropriate_targets.append(t)
    
    return appropriate_targets, inappropriate_targets

def suggest_appropriate_targets(df):
    """Sugere targets apropriados para an√°lise baseado nas caracter√≠sticas do dataset."""
    suggestions = []
    
    for col in df.columns:
        # Ignora colunas que s√£o chaves
        common_keys = {'id_', '_id', 'cod_', '_cod', 'key', '_key', 'numero', '_numero', 'cpf', 'cnpj', 'matricula'}
        if any(keyword in col.lower() for keyword in common_keys):
            continue
        
        # Verifica tipo de dados
        dtype = df[col].dtype
        
        # Para colunas num√©ricas
        if pd.api.types.is_numeric_dtype(dtype):
            unique_ratio = df[col].nunique() / len(df)
            std_val = df[col].std()
            
            # Prioridade 1: Valores cont√≠nuos com boa varia√ß√£o (regress√£o)
            # Crit√©rio mais flex√≠vel: ou tem boa varia√ß√£o (std > 0) E (unique_ratio > 0.05 OU muitos valores √∫nicos > 1000)
            if std_val > 0 and (unique_ratio > 0.05 or df[col].nunique() > 1000):
                priority = 1
                suggestions.append({
                    'coluna': col,
                    'tipo': 'Regress√£o',
                    'razao': f'Valores cont√≠nuos (varia√ß√£o: {std_val:.2f}, {df[col].nunique()} valores √∫nicos)',
                    'priority': priority,
                    'std': std_val
                })
            # Prioridade 2: Poucas categorias (classifica√ß√£o)
            elif df[col].nunique() <= 10:
                priority = 2
                suggestions.append({
                    'coluna': col,
                    'tipo': 'Classifica√ß√£o',
                    'razao': f'{df[col].nunique()} categorias distintas',
                    'priority': priority,
                    'unique_count': df[col].nunique()
                })
            # Prioridade 3: Outras colunas num√©ricas
            else:
                priority = 3
                suggestions.append({
                    'coluna': col,
                    'tipo': 'Regress√£o/Classifica√ß√£o',
                    'razao': f'Valores num√©ricos ({df[col].nunique()} valores √∫nicos)',
                    'priority': priority
                })
    
    # Ordena por prioridade (1 = melhor, 3 = pior) e desempata por desvio padr√£o (para regress√£o)
    suggestions.sort(key=lambda x: (x['priority'], -x.get('std', 0) if 'std' in x else 0, -x.get('unique_count', 0) if 'unique_count' in x else 0))
    
    return suggestions[:5]  # Retorna at√© 5 sugest√µes

def run_analytics(df, target):
    # Primeiro valida os targets
    appropriate_targets, inappropriate_targets = validate_targets(df, target)
    
    if inappropriate_targets:
        console.print(f"\n[bold yellow]‚ö†Ô∏è  Aten√ß√£o: Alguns targets podem n√£o ser apropriados para an√°lise:[/bold yellow]")
        for t in inappropriate_targets:
            console.print(f"  ‚Ä¢ {t}")
        
        # Sugere targets apropriados
        suggestions = suggest_appropriate_targets(df)
        
        if suggestions:
            console.print(f"\n[bold cyan]üí° Sugest√µes de targets apropriados:[/bold cyan]")
            for i, s in enumerate(suggestions, 1):
                console.print(f"  {i}. {s['coluna']} ({s['tipo']}) - {s['razao']}")
        
        # Oferece op√ß√µes interativas ao usu√°rio
        console.print(f"\n[bold]üìã Op√ß√µes dispon√≠veis:[/bold]")
        console.print(f"[cyan]1.[/cyan] Continuar com os targets informados (apesar da advert√™ncia)")
        
        if suggestions:
            # Cria op√ß√µes para cada sugest√£o
            for i, s in enumerate(suggestions, 2):
                console.print(f"[cyan]{i}.[/cyan] Usar target: [bold]{s['coluna']}[/bold] ({s['tipo']})")
            
            # Op√ß√£o para usar todas as sugest√µes
            last_option = len(suggestions) + 2
            console.print(f"[cyan]{last_option}.[/cyan] Usar todos os targets sugeridos")
            console.print(f"[cyan]{last_option + 1}.[/cyan] Cancelar an√°lise")
            
            console.print(f"\n[bold]Escolha uma op√ß√£o (1-{last_option + 1}):[/bold] ", end="")
            
            try:
                choice = input().strip()
                if choice == str(last_option + 1):  # Cancelar
                    console.print("[red]‚ùå An√°lise cancelada pelo usu√°rio.[/red]")
                    return None, "Cancelado"
                elif choice == str(last_option):  # Usar todos os targets sugeridos
                    new_targets = [s['coluna'] for s in suggestions]
                    console.print(f"[green]‚úì Usando todos os targets sugeridos: {', '.join(new_targets)}[/green]")
                    target = ','.join(new_targets)
                elif choice.isdigit() and 2 <= int(choice) <= last_option - 1:  # Usar uma sugest√£o espec√≠fica
                    idx = int(choice) - 2
                    new_target = suggestions[idx]['coluna']
                    console.print(f"[green]‚úì Usando target sugerido: {new_target}[/green]")
                    target = new_target
                elif choice == "1":  # Continuar com targets informados
                    console.print(f"[yellow]‚ö†Ô∏è  Continuando com targets informados: {target}[/yellow]")
                else:
                    console.print(f"[yellow]‚ö†Ô∏è  Op√ß√£o inv√°lida. Continuando com targets informados: {target}[/yellow]")
            except KeyboardInterrupt:
                console.print("[red]‚ùå An√°lise cancelada pelo usu√°rio.[/red]")
                return None, "Cancelado"
            except Exception as e:
                console.print(f"[yellow]‚ö†Ô∏è  Erro na sele√ß√£o: {e}. Continuando com targets informados: {target}[/yellow]")
        else:
            console.print(f"[cyan]2.[/cyan] Cancelar an√°lise")
            console.print(f"\n[bold]Escolha uma op√ß√£o (1-2):[/bold] ", end="")
            
            try:
                choice = input().strip()
                if choice == "2":
                    console.print("[red]‚ùå An√°lise cancelada pelo usu√°rio.[/red]")
                    return None, "Cancelado"
                elif choice != "1":
                    console.print(f"[yellow]‚ö†Ô∏è  Op√ß√£o inv√°lida. Continuando com targets informados: {target}[/yellow]")
            except KeyboardInterrupt:
                console.print("[red]‚ùå An√°lise cancelada pelo usu√°rio.[/red]")
                return None, "Cancelado"
            except Exception as e:
                console.print(f"[yellow]‚ö†Ô∏è  Erro na sele√ß√£o: {e}. Continuando com targets informados: {target}[/yellow]")
    
    # Verifica se target cont√©m m√∫ltiplos campos separados por v√≠rgula
    if ',' in target:
        targets = [t.strip() for t in target.split(',')]
        console.print(f"\n[bold yellow]üîç Analisando relev√¢ncia e dire√ß√£o para {len(targets)} targets: {', '.join(targets)}...[/bold yellow]")
        
        # An√°lise individual para cada target
        all_results = {}
        for single_target in targets:
            console.print(f"\n[cyan]‚ñ∂Ô∏è  Analisando individualmente: {single_target}[/cyan]")
            ranking, tipo = _run_single_analytics(df, single_target)
            all_results[single_target] = {'ranking': ranking, 'tipo': tipo}
        
        # An√°lise multivariada - intera√ß√µes entre targets
        console.print(f"\n[bold magenta]üîó Analisando intera√ß√µes entre {len(targets)} targets...[/bold magenta]")
        multivariate_results = _run_multivariate_analytics(df, targets)
        
        return {
            'individual': all_results,
            'multivariate': multivariate_results
        }, "M√∫ltiplos"
    else:
        # Caso √∫nico target (compatibilidade com vers√£o anterior)
        console.print(f"\n[bold yellow]üîç Analisando relev√¢ncia e dire√ß√£o para: {target}...[/bold yellow]")
        ranking, tipo = _run_single_analytics(df, target)
        return {target: {'ranking': ranking, 'tipo': tipo}}, tipo

def _run_single_analytics(df, target):
    """Fun√ß√£o auxiliar para an√°lise de um √∫nico target."""
    # 1. Verifica se o target existe no DataFrame original
    if target not in df.columns:
        # Tenta encontrar colunas similares
        similar_cols = [col for col in df.columns if target.lower() in col.lower()]
        if similar_cols:
            console.print(f"[yellow]‚ö†Ô∏è  Target '{target}' n√£o encontrado. Usando coluna similar: {similar_cols[0]}[/yellow]")
            target = similar_cols[0]
        else:
            raise ValueError(f"Target '{target}' n√£o encontrado no DataFrame")
    
    # 2. Verifica o tipo da coluna target e d√° feedback ao usu√°rio
    target_dtype = df[target].dtype
    is_numeric = pd.api.types.is_numeric_dtype(target_dtype)
    is_integer = pd.api.types.is_integer_dtype(target_dtype)
    
    console.print(f"[cyan]üìä Tipo da coluna '{target}': {target_dtype}[/cyan]")
    
    if is_numeric:
        if is_integer:
            console.print(f"[green]‚úì Coluna '{target}' √© num√©rica (inteiro)[/green]")
        else:
            console.print(f"[green]‚úì Coluna '{target}' √© num√©rica (decimal)[/green]")
    else:
        console.print(f"[yellow]‚ö†Ô∏è  Coluna '{target}' n√£o √© num√©rica[/yellow]")
        console.print(f"[cyan]Valores √∫nicos (primeiros 5): {df[target].unique()[:5]}[/cyan]")
        console.print(f"\n[bold green]ÔøΩ RECOMENDA√á√ÉO:[/bold green]")
        console.print(f"Para melhor an√°lise, considere transformar '{target}' em uma coluna num√©rica:")
        console.print(f"1. Crie uma nova coluna num√©rica baseada em '{target}'")
        console.print(f"2. Use uma coluna j√° existente que seja num√©rica")
        console.print(f"3. Transforme '{target}' em uma coluna num√©rica usando:")
        console.print(f"   - C√≥digos num√©ricos para categorias")
        console.print(f"   - Contagens ou frequ√™ncias")
        console.print(f"   - Valores bin√°rios (0/1)")
        console.print(f"\n[bold yellow]üìù O programa tentar√° converter automaticamente para an√°lise...[/bold yellow]")
    
    # 3. Cria uma c√≥pia do DataFrame para processamento
    df_ml = df.copy()
    
    # 4. Garante que o target seja num√©rico (transforma categ√≥ricos)
    if df_ml[target].dtype == 'object' or df_ml[target].dtype == 'string' or df_ml[target].nunique() <= 20:
        # Abordagem robusta: cria uma nova coluna com IDs num√©ricos
        # Isso evita o erro "Cannot setitem on a Categorical with a new category"
        unique_vals = df_ml[target].astype(str).unique()
        mapping = {val: i for i, val in enumerate(unique_vals)}
        
        # Cria uma nova coluna com sufixo '_id' para manter a original
        new_target_name = f"{target}_id"
        
        # Usa .replace() em vez de .map() para evitar NaN
        # .replace() substitui valores que n√£o est√£o no mapeamento por NaN, ent√£o preenchemos depois
        df_ml[new_target_name] = df_ml[target].astype(str).replace(mapping)
        
        # Remove a coluna original e renomeia a nova para o nome do target
        df_ml = df_ml.drop(columns=[target])
        df_ml = df_ml.rename(columns={new_target_name: target})
        
        console.print(f"[green]‚úì Target '{target}' transformado em IDs num√©ricos ({len(mapping)} categorias)[/green]")
    
    # 4. Filtra apenas colunas num√©ricas para an√°lise (exclui o target da filtragem)
    # Primeiro mantemos o target transformado (cria uma c√≥pia expl√≠cita para evitar refer√™ncias)
    target_series = df_ml[target].copy()
    
    # Depois filtramos as features (todas as outras colunas)
    features_df = df_ml.drop(columns=[target]).select_dtypes(include=['number', 'bool']).copy()
    
    # Recria o DataFrame com features num√©ricas + target transformado
    df_ml = pd.concat([features_df, target_series], axis=1)
    
    # 5. Limpeza de dados (essencial para correla√ß√£o n√£o dar NaN)
    df_ml = df_ml.fillna(0)
    
    X = df_ml.drop(columns=[target])
    y = df_ml[target]

    # 6. Treino do Modelo
    if y.nunique() <= 2:
        model = RandomForestClassifier(n_estimators=100, random_state=123)
        tipo = "Classifica√ß√£o"
    else:
        model = RandomForestRegressor(n_estimators=100, random_state=123)
        tipo = "Regress√£o"

    model.fit(X, y)

    # 7. C√°lculo de Import√¢ncia + Dire√ß√£o usando fun√ß√£o segura
    ranking_data = []
    for i, col in enumerate(X.columns):
        # Usa fun√ß√£o segura para evitar warnings
        corr = _safe_correlation(X[col], y)
        
        ranking_data.append({
            'Feature': col,
            'Importance': model.feature_importances_[i],
            'Correlation': corr
        })
    
    ranking = pd.DataFrame(ranking_data)
    ranking = ranking.sort_values(by='Importance', ascending=False).head(10)
    return ranking, tipo

def _safe_correlation(x, y):
    """C√°lculo seguro de correla√ß√£o que evita warnings de divis√£o por zero."""
    # Limpa dados
    x_clean = x.replace([np.inf, -np.inf], np.nan).fillna(0)
    y_clean = y.replace([np.inf, -np.inf], np.nan).fillna(0)
    
    # Calcula desvio padr√£o
    std_x = x_clean.std()
    std_y = y_clean.std()
    
    # Se algum desvio padr√£o for zero, retorna 0
    if std_x == 0 or std_y == 0:
        return 0.0
    
    # Calcula covari√¢ncia
    covariance = ((x_clean - x_clean.mean()) * (y_clean - y_clean.mean())).mean()
    
    # Calcula correla√ß√£o
    correlation = covariance / (std_x * std_y)
    
    # Garante que n√£o seja NaN
    return 0.0 if pd.isna(correlation) else correlation

def _run_multivariate_analytics(df, targets):
    """An√°lise multivariada - identifica padr√µes complexos entre m√∫ltiplos targets."""
    # 1. Prepara os dados
    df_ml = df.copy()
    
    # 2. Garante que todos os targets sejam num√©ricos
    for target in targets:
        if target not in df_ml.columns:
            continue
            
        if df_ml[target].dtype == 'object' or df_ml[target].dtype == 'string' or df_ml[target].nunique() <= 20:
            unique_vals = df_ml[target].astype(str).unique()
            mapping = {val: i for i, val in enumerate(unique_vals)}
            new_target_name = f"{target}_id"
            df_ml[new_target_name] = df_ml[target].astype(str).replace(mapping)
            df_ml = df_ml.drop(columns=[target])
            df_ml = df_ml.rename(columns={new_target_name: target})
    
    # 3. Filtra apenas colunas num√©ricas (exclui os targets temporariamente)
    target_series = df_ml[targets].copy()
    features_df = df_ml.drop(columns=targets).select_dtypes(include=['number', 'bool']).copy()
    
    # 4. Recria DataFrame com features + targets
    df_ml = pd.concat([features_df, target_series], axis=1)
    
    # 5. Limpeza robusta de dados para evitar NaN/Inf
    # Remove infinitos e substitui NaN por 0
    df_ml = df_ml.replace([np.inf, -np.inf], np.nan)
    df_ml = df_ml.fillna(0)
    
    # 6. An√°lise de correla√ß√£o entre targets com tratamento de erros robusto
    try:
        # Verifica se h√° colunas com desvio padr√£o zero antes do c√°lculo
        targets_data = df_ml[targets].copy()
        
        # Remove colunas com desvio padr√£o zero (causam divis√£o por zero)
        valid_targets = []
        for target in targets:
            if target in targets_data.columns:
                std_val = targets_data[target].std()
                if std_val == 0 or pd.isna(std_val):
                    console.print(f"[yellow]‚ö†Ô∏è  Target '{target}' tem desvio padr√£o zero, removendo da an√°lise multivariada[/yellow]")
                else:
                    valid_targets.append(target)
        
        if len(valid_targets) >= 2:
            # Calcula correla√ß√£o apenas com targets v√°lidos
            correlation_matrix = targets_data[valid_targets].corr()
            # Substitui NaN na matriz de correla√ß√£o por 0
            correlation_matrix = correlation_matrix.fillna(0)
            
            # Se removemos alguns targets, preenche a matriz completa com zeros
            if len(valid_targets) < len(targets):
                # Cria matriz com tipo float para evitar warning de tipo
                full_matrix = pd.DataFrame(0.0, index=targets, columns=targets, dtype=float)
                for i, t in enumerate(targets):
                    full_matrix.loc[t, t] = 1.0
                # Copia os valores calculados para os targets v√°lidos
                for t1 in valid_targets:
                    for t2 in valid_targets:
                        full_matrix.loc[t1, t2] = float(correlation_matrix.loc[t1, t2])
                correlation_matrix = full_matrix
        else:
            console.print(f"[yellow]‚ö†Ô∏è  N√£o h√° targets suficientes com vari√¢ncia para an√°lise multivariada[/yellow]")
            correlation_matrix = pd.DataFrame(0.0, index=targets, columns=targets, dtype=float)
            for i, t in enumerate(targets):
                correlation_matrix.loc[t, t] = 1.0
                
    except Exception as e:
        console.print(f"[yellow]‚ö†Ô∏è  Erro ao calcular correla√ß√µes: {e}[/yellow]")
        # Cria matriz de correla√ß√£o vazia com tipo float
        correlation_matrix = pd.DataFrame(0.0, index=targets, columns=targets, dtype=float)
        for i, t in enumerate(targets):
            correlation_matrix.loc[t, t] = 1.0
    
    # 6. Identifica features que influenciam m√∫ltiplos targets simultaneamente
    multivariate_insights = []
    
    for feature in features_df.columns:
        # Calcula correla√ß√£o com cada target usando fun√ß√£o segura
        correlations = {}
        for target in targets:
            if feature in df_ml.columns and target in df_ml.columns:
                # Usa fun√ß√£o segura que evita warnings
                corr = _safe_correlation(df_ml[feature], df_ml[target])
                correlations[target] = corr
        
        # Identifica padr√µes:
        # 1. Features que influenciam todos os targets na mesma dire√ß√£o
        # 2. Features que t√™m efeitos opostos em diferentes targets
        # 3. Features com forte influ√™ncia em pelo menos 2 targets
        
        if len(correlations) >= 2:
            # Verifica se influencia na mesma dire√ß√£o
            positive_count = sum(1 for corr in correlations.values() if corr > 0.1)
            negative_count = sum(1 for corr in correlations.values() if corr < -0.1)
            strong_count = sum(1 for corr in correlations.values() if abs(corr) > 0.3)
            
            if strong_count >= 2 or (positive_count >= 2) or (negative_count >= 2):
                # Calcula impacto m√©dio
                avg_impact = sum(abs(corr) for corr in correlations.values()) / len(correlations)
                
                # Determina padr√£o
                if positive_count >= 2 and negative_count == 0:
                    pattern = "Influencia positiva m√∫ltipla"
                elif negative_count >= 2 and positive_count == 0:
                    pattern = "Influencia negativa m√∫ltipla"
                elif positive_count >= 1 and negative_count >= 1:
                    pattern = "Efeito misto (oposto)"
                else:
                    pattern = "Influencia forte m√∫ltipla"
                
                multivariate_insights.append({
                    'Feature': feature,
                    'Pattern': pattern,
                    'AvgImpact': avg_impact,
                    'Correlations': correlations,
                    'StrongTargets': strong_count
                })
    
    # 7. Ordena por impacto e n√∫mero de targets afetados
    multivariate_insights.sort(key=lambda x: (x['StrongTargets'], x['AvgImpact']), reverse=True)
    
    return {
        'correlation_matrix': correlation_matrix,
        'multivariate_insights': multivariate_insights[:20],  # Top 20 insights
        'target_interactions': _analyze_target_interactions(correlation_matrix, targets)
    }

def _analyze_target_interactions(correlation_matrix, targets):
    """Analisa intera√ß√µes entre os pr√≥prios targets."""
    interactions = []
    
    for i, target1 in enumerate(targets):
        for j, target2 in enumerate(targets):
            if i < j:  # Evita duplicatas
                corr = correlation_matrix.loc[target1, target2]
                
                if abs(corr) > 0.5:
                    strength = "Forte"
                elif abs(corr) > 0.3:
                    strength = "Moderada"
                elif abs(corr) > 0.1:
                    strength = "Fraca"
                else:
                    continue
                
                direction = "Positiva" if corr > 0 else "Negativa"
                
                interactions.append({
                    'Target1': target1,
                    'Target2': target2,
                    'Correlation': corr,
                    'Strength': strength,
                    'Direction': direction,
                    'Interpretation': f"{target1} e {target2} t√™m rela√ß√£o {direction.lower()} {strength.lower()}"
                })
    
    return interactions

def export_to_markdown(results, tipo_ml, projeto, target, ts):
    """Gera um arquivo .md com tratamento robusto de erros e codifica√ß√£o."""
    filename = f"result_{projeto}_{ts}.md"
    filepath = os.path.join("resultados", filename)
    
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"# Relatorio de Inteligencia: {projeto.upper()}\n\n")
            f.write(f"**Alvos Analisados:** {target} | **Tipo:** {tipo_ml}\n\n")
            
            # Se for an√°lise m√∫ltipla, mostra um sum√°rio executivo primeiro
            if tipo_ml == "M√∫ltiplos":
                # Extrai targets da string
                targets = [t.strip() for t in target.split(',')]
                
                f.write("## üìä Sum√°rio Executivo - An√°lise Multivariada\n\n")
                f.write(f"Foram analisados {len(targets)} targets simultaneamente:\n\n")
                
                # An√°lise individual
                if 'individual' in results:
                    for target_name, result_data in results['individual'].items():
                        f.write(f"- **{target_name}**: {result_data['tipo']} (Top 10 insights)\n")
                
                # An√°lise multivariada
                if 'multivariate' in results:
                    multivariate = results['multivariate']
                    f.write(f"\n**üîó Intera√ß√µes entre targets:**\n")
                    
                    if multivariate['target_interactions']:
                        f.write(f"- Foram identificadas {len(multivariate['target_interactions'])} intera√ß√µes significativas entre targets\n")
                    
                    if multivariate['multivariate_insights']:
                        f.write(f"- {len(multivariate['multivariate_insights'])} features influenciam m√∫ltiplos targets simultaneamente\n")
                
                f.write("\n---\n\n")
                
                # Se√ß√£o de an√°lise multivariada
                if 'multivariate' in results:
                    multivariate = results['multivariate']
                    
                    # 1. Intera√ß√µes entre targets
                    if multivariate['target_interactions']:
                        f.write("## üîó Intera√ß√µes entre Targets\n\n")
                        f.write("| Target 1 | Target 2 | Correla√ß√£o | For√ßa | Dire√ß√£o |\n")
                        f.write("| :--- | :--- | :--- | :--- | :--- |\n")
                        
                        for interaction in multivariate['target_interactions']:
                            f.write(f"| {interaction['Target1']} | {interaction['Target2']} | {interaction['Correlation']:.3f} | {interaction['Strength']} | {interaction['Direction']} |\n")
                        
                        f.write("\n")
                    
                    # 2. Insights multivariados
                    if multivariate['multivariate_insights']:
                        f.write("## üß© Insights Multivariados (Padr√µes Complexos)\n\n")
                        f.write("Features que influenciam m√∫ltiplos targets simultaneamente:\n\n")
                        f.write("| Feature | Padr√£o | Impacto M√©dio | Targets Fortes | Correla√ß√µes |\n")
                        f.write("| :--- | :--- | :--- | :--- | :--- |\n")
                        
                        for insight in multivariate['multivariate_insights'][:10]:  # Top 10
                            traducao = traduzir_feature(insight['Feature'])
                            correlations_str = ", ".join([f"{t}: {c:.2f}" for t, c in insight['Correlations'].items()])
                            f.write(f"| {traducao} | {insight['Pattern']} | {insight['AvgImpact']:.3f} | {insight['StrongTargets']} | {correlations_str} |\n")
                        
                        f.write("\n---\n\n")
                
                # An√°lise individual para cada target
                if 'individual' in results:
                    for target_name, result_data in results['individual'].items():
                        ranking = result_data['ranking']
                        target_tipo = result_data['tipo']
                        
                        f.write(f"## üéØ An√°lise Individual para: {target_name} ({target_tipo})\n\n")
                        
                        f.write("| Rank | Insight | Impacto | Tendencia |\n")
                        f.write("| :--- | :--- | :--- | :--- |\n")
                        
                        for i, row in enumerate(ranking.itertuples(), 1):
                            traducao = traduzir_feature(row.Feature)
                            seta = "(+)" if row.Correlation > 0 else "(-)"
                            relacao = "aumenta" if row.Correlation > 0 else "diminui"
                            tendencia = f"{seta} Quanto maior, mais {relacao} o(a) {target_name}"
                            
                            f.write(f"| #{i} | {traducao} | {formatar_impacto(row.Importance)} | {tendencia} |\n")
                        
                        f.write("\n")
            else:
                # Caso √∫nico target
                for target_name, result_data in results.items():
                    ranking = result_data['ranking']
                    target_tipo = result_data['tipo']
                    
                    f.write("## Top 10 Insights e Tendencias\n\n")
                    
                    f.write("| Rank | Insight | Impacto | Tendencia |\n")
                    f.write("| :--- | :--- | :--- | :--- |\n")
                    
                    for i, row in enumerate(ranking.itertuples(), 1):
                        traducao = traduzir_feature(row.Feature)
                        seta = "(+)" if row.Correlation > 0 else "(-)"
                        relacao = "aumenta" if row.Correlation > 0 else "diminui"
                        tendencia = f"{seta} Quanto maior, mais {relacao} o(a) {target_name}"
                        
                        f.write(f"| #{i} | {traducao} | {formatar_impacto(row.Importance)} | {tendencia} |\n")
                    
                    f.write("\n")
            
            f.write(f"\n\n--- \n*Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}*")
        return filename
    except Exception as e:
        console.print(f"[red]Erro ao gravar Markdown: {e}[/red]")
        return None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--projeto", required=True)
    parser.add_argument("--target", required=True)
    args = parser.parse_args()

    rules = parse_mapping_file()
    if not rules: return

    console.print(Panel(f"üöÄ [bold]DiscoverySpark Engine[/bold] v3.0\nProjeto: {args.projeto}", style="blue"))
    
    es = ft.EntitySet(id=args.projeto)
    parent_table = ""

    # 1. Carga
    for r in rules:
        df = pd.read_csv(f"datasets/{r['name']}.csv")
        for col in df.columns:
            if 'data' in col.lower() or 'date' in col.lower():
                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S', errors='coerce')
        
        # Featuretools 1.31.0+ requer woodwork obrigatoriamente
        # Abordagem direta: inicializa woodwork explicitamente
        
        # Debug: mostra tipos de dados
        console.print(f"[yellow]Tipos de dados para {r['name']}:[/yellow]")
        for col in df.columns:
            console.print(f"  {col}: {df[col].dtype}")
        
        # Converte tipos problem√°ticos para garantir compatibilidade
        for col in df.columns:
            if df[col].dtype == 'object' or df[col].dtype == 'string':
                df[col] = df[col].astype('str')
        
        # Abordagem: cria uma c√≥pia limpa do DataFrame e remove woodwork
        # O featuretools 1.31.0 requer woodwork, mas podemos trabalhar com c√≥pias limpas
        df_clean = df.copy()
        
        # Remove qualquer atributo woodwork que possa existir
        if hasattr(df_clean, 'ww'):
            # Cria um novo DataFrame a partir de um dicion√°rio para evitar woodwork
            data_dict = {}
            for col in df_clean.columns:
                data_dict[col] = df_clean[col].values
            
            df_clean = pd.DataFrame(data_dict)
        
        console.print(f"[green]‚úì DataFrame limpo criado para {r['name']}[/green]")
        
        if r['role'] == 'pai':
            parent_table = r['name']
            # Para tabelas pai, usa a chave existente
            try:
                es.add_dataframe(dataframe_name=r['name'], dataframe=df_clean, index=r['keys'][0])
                console.print(f"[green]‚úì[/green] Tabela '{r['name']}' carregada.")
            except Exception as e:
                console.print(f"[red]‚ùå Erro ao adicionar tabela '{r['name']}': {e}[/red]")
                raise
        else:
            # Para tabelas filhas, cria um √≠ndice manualmente ANTES de adicionar
            index_name = f"id_auto_{r['name']}"
            df_clean[index_name] = range(len(df_clean))
            try:
                es.add_dataframe(dataframe_name=r['name'], dataframe=df_clean, index=index_name)
                console.print(f"[green]‚úì[/green] Tabela '{r['name']}' carregada.")
            except Exception as e:
                console.print(f"[red]‚ùå Erro ao adicionar tabela '{r['name']}': {e}[/red]")
                raise

    # 2. Relacionamentos
    pai = [r for r in rules if r['role'] == 'pai'][0]
    for f in [r for r in rules if r['role'] == 'filho']:
        es.add_relationship(pai['name'], pai['keys'][0], f['name'], f['keys'][0])
    
    # 3. DFS
    console.print("\n[bold magenta]‚öôÔ∏è  Sintetizando vari√°veis...[/bold magenta]")
    feature_matrix, _ = ft.dfs(entityset=es, target_dataframe_name=parent_table, max_depth=2)

# 4. Analytics
    results, tipo_ml = run_analytics(feature_matrix, args.target)
    
    # Verifica se o usu√°rio cancelou a an√°lise
    if results is None:
        console.print("[yellow]üìù An√°lise n√£o realizada (cancelada pelo usu√°rio).[/yellow]")
        return

    # 5. Sa√≠da (Invertemos a ordem para garantir a tentativa do MD)
    ts = datetime.now().strftime("%Y%m%d%H%M%S")
    
    console.print("[yellow]üíæ Gravando arquivos de sa√≠da...[/yellow]")
    
    # Tenta MD primeiro
    md_file = export_to_markdown(results, tipo_ml, args.projeto, args.target, ts)
    if md_file:
        console.print(f"[green]‚úì Relat√≥rio MD criado: {md_file}[/green]")
    
    # Tenta CSV depois
    csv_path = f"resultados/result_{args.projeto}_{ts}.csv"
    feature_matrix.to_csv(csv_path)
    console.print(f"[green]‚úì Dataset CSV criado: {csv_path}[/green]")

    # Exibe resultados no terminal
    if tipo_ml == "M√∫ltiplos":
        # An√°lise individual para cada target
        if 'individual' in results:
            for target_name, result_data in results['individual'].items():
                ranking = result_data['ranking']
                target_tipo = result_data['tipo']
                
                res_table = Table(title=f"Resumo de Impacto para: {target_name} ({target_tipo})")
                res_table.add_column("Insight", style="white")
                res_table.add_column("Impacto", style="green")
                res_table.add_column("Tend√™ncia", style="cyan")
                
                for row in ranking.itertuples():
                    traducao = traduzir_feature(row.Feature)
                    seta = "‚ÜóÔ∏è" if row.Correlation > 0 else "‚ÜòÔ∏è"
                    relacao = "aumenta" if row.Correlation > 0 else "diminui"
                    tendencia = f"{seta} {relacao} {target_name}"
                    
                    res_table.add_row(traducao, formatar_impacto(row.Importance), tendencia)
                
                console.print(res_table)
        
        # An√°lise multivariada
        if 'multivariate' in results:
            multivariate = results['multivariate']
            
            # Intera√ß√µes entre targets
            if multivariate['target_interactions']:
                inter_table = Table(title="üîó Intera√ß√µes entre Targets")
                inter_table.add_column("Target 1", style="cyan")
                inter_table.add_column("Target 2", style="cyan")
                inter_table.add_column("Correla√ß√£o", style="yellow")
                inter_table.add_column("For√ßa", style="green")
                inter_table.add_column("Dire√ß√£o", style="magenta")
                
                for interaction in multivariate['target_interactions']:
                    inter_table.add_row(
                        interaction['Target1'],
                        interaction['Target2'],
                        f"{interaction['Correlation']:.3f}",
                        interaction['Strength'],
                        interaction['Direction']
                    )
                
                console.print(inter_table)
            
            # Insights multivariados
            if multivariate['multivariate_insights']:
                multi_table = Table(title="üß© Insights Multivariados (Top 5)")
                multi_table.add_column("Feature", style="white")
                multi_table.add_column("Padr√£o", style="cyan")
                multi_table.add_column("Impacto M√©dio", style="green")
                multi_table.add_column("Targets Fortes", style="yellow")
                
                for insight in multivariate['multivariate_insights'][:5]:
                    traducao = traduzir_feature(insight['Feature'])
                    multi_table.add_row(
                        traducao,
                        insight['Pattern'],
                        f"{insight['AvgImpact']:.3f}",
                        str(insight['StrongTargets'])
                    )
                
                console.print(multi_table)
    else:
        # Caso √∫nico target
        for target_name, result_data in results.items():
            ranking = result_data['ranking']
            target_tipo = result_data['tipo']
            
            res_table = Table(title=f"Resumo de Impacto para: {target_name} ({target_tipo})")
            res_table.add_column("Insight", style="white")
            res_table.add_column("Impacto", style="green")
            res_table.add_column("Tend√™ncia", style="cyan")
            
            for row in ranking.itertuples():
                traducao = traduzir_feature(row.Feature)
                seta = "‚ÜóÔ∏è" if row.Correlation > 0 else "‚ÜòÔ∏è"
                relacao = "aumenta" if row.Correlation > 0 else "diminui"
                tendencia = f"{seta} {relacao} {target_name}"
                
                res_table.add_row(traducao, formatar_impacto(row.Importance), tendencia)
            
            console.print(res_table)

    console.print(f"\n[bold green]‚úÖ Relat√≥rios gerados em /resultados![/bold green]")

if __name__ == "__main__":
    setup_environment()
    try:
        main()
    except Exception as e:
        console.print(f"[red]Erro fatal: {e}[/red]")